{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Curvas PR y ROC: Evaluación de Modelos de Clasificación\n",
    "\n",
    "## Introducción\n",
    "\n",
    "Cuando evaluamos modelos de clasificación, las curvas **ROC** y **PR** son herramientas esenciales para visualizar y entender el rendimiento del modelo más allá de métricas simples como la precisión y el recall. Ambas curvas nos ayudan a determinar cómo se comporta un modelo a medida que cambia su umbral de clasificación.\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Curva ROC (Receiver Operating Characteristic)\n",
    "\n",
    "### **Descripción**\n",
    "La **curva ROC** es una representación gráfica que muestra la relación entre la **tasa de verdaderos positivos** (TPR) y la **tasa de falsos positivos** (FPR) a diferentes umbrales de decisión. El área bajo la curva ROC, conocida como **AUC-ROC**, es una métrica que resume el rendimiento del modelo; un valor más cercano a 1 indica un mejor rendimiento.\n",
    "\n",
    "### **Fórmulas Clave**\n",
    "- **TPR (Tasa de Verdaderos Positivos)**:\n",
    "$$\n",
    "TPR = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "- **FPR (Tasa de Falsos Positivos)**:\n",
    "$$\n",
    "FPR = \\frac{FP}{FP + TN}\n",
    "$$\n",
    "\n",
    "Donde:\n",
    "- $TP$ = Verdaderos positivos\n",
    "- $FP$ = Falsos positivos\n",
    "- $TN$ = Verdaderos negativos\n",
    "- $FN$ = Falsos negativos\n",
    "\n",
    "### **Método de Feynman**\n",
    "Imagina que tienes un detector de incendios. Si aumentas la sensibilidad, capturará más incendios (TP) pero también dará más falsas alarmas (FP). La curva ROC muestra cómo varían las verdaderas detecciones y las falsas alarmas al cambiar la sensibilidad.\n",
    "\n",
    "### **Aplicación**\n",
    "- Ideal para problemas de clasificación binaria.\n",
    "- Evaluación general de modelos donde el balance entre TPR y FPR es importante.\n",
    "\n",
    "---\n",
    "\n",
    "## 2. Curva PR (Precision-Recall)\n",
    "\n",
    "### **Descripción**\n",
    "La **curva PR** muestra la relación entre la **precisión** y el **recall** a diferentes umbrales. Es especialmente útil para problemas con clases desbalanceadas, ya que se enfoca en la clase positiva y en la capacidad del modelo de mantener una alta precisión a medida que se incrementa el recall.\n",
    "\n",
    "### **Fórmulas Clave**\n",
    "- **Precisión**:\n",
    "$$\n",
    "\\text{Precisión} = \\frac{TP}{TP + FP}\n",
    "$$\n",
    "\n",
    "- **Recall**:\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$\n",
    "\n",
    "### **Método de Feynman**\n",
    "Imagina que tienes un tamiz para encontrar pepitas de oro en la arena. Si tu tamiz es muy fino, solo capturarás las pepitas más grandes (alta precisión, bajo recall). Si usas un tamiz más grueso, capturarás más pepitas (alto recall), pero también más arena (baja precisión). La curva PR muestra cómo cambian la precisión y el recall con el tamaño del tamiz (umbral).\n",
    "\n",
    "### **Aplicación**\n",
    "- Es más relevante que la curva ROC cuando hay un fuerte desbalance de clases.\n",
    "- Útil para problemas donde el costo de los falsos positivos o falsos negativos es alto.\n",
    "\n",
    "---\n",
    "\n",
    "## Comparación entre Curva ROC y Curva PR\n",
    "\n",
    "| **Métrica**            | **Curva ROC**                                       | **Curva PR**                                         |\n",
    "|------------------------|------------------------------------------------------|------------------------------------------------------|\n",
    "| **Cuando usarla**      | Cuando hay un balance entre clases.                 | Cuando hay un desbalance de clases.                  |\n",
    "| **Interpretación**     | Muestra TPR vs. FPR a diferentes umbrales.          | Muestra precisión vs. recall a diferentes umbrales.  |\n",
    "| **Métrica resumen**    | AUC-ROC (Área bajo la curva ROC).                   | AUC-PR (Área bajo la curva PR).                      |\n",
    "| **Fuerte desbalance**  | Puede ser engañosa en este caso.                    | Ofrece una mejor representación de la clase positiva.|\n",
    "\n",
    "---\n",
    "\n",
    "## Ejemplo Práctico en Python\n",
    "\n",
    "### Configuración del entorno\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, precision_recall_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generar un conjunto de datos de clasificación binaria\n",
    "X, y = make_classification(n_samples=1000, n_classes=2, weights=[0.9, 0.1], random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Modelo de clasificación\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predicciones de probabilidad\n",
    "y_scores = model.predict_proba(X_test)[:, 1]"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
